{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c562892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 1: Setup and Initialization\n",
    "import numpy as np\n",
    "from petsc4py import PETSc\n",
    "from mpi4py import MPI\n",
    "import ufl\n",
    "from dolfinx import mesh, fem\n",
    "from dolfinx.fem.petsc import assemble_matrix, assemble_vector, apply_lifting, create_vector, set_bc\n",
    "\n",
    "# Domain and Function Space Setup\n",
    "nx, ny = 5, 5\n",
    "domain = mesh.create_unit_square(MPI.COMM_WORLD, nx, ny, mesh.CellType.triangle)\n",
    "V = fem.functionspace(domain, (\"Lagrange\", 1))\n",
    "\n",
    "# Exact Solution Class\n",
    "class exact_solution():\n",
    "    def __init__(self, alpha, beta, t):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.t = t\n",
    "\n",
    "    def __call__(self, x):\n",
    "        return -np.sin(np.pi*self.alpha*x[0])*np.sin(np.pi*self.beta*x[1])* np.exp(-(self.alpha**2 + self.beta**2)*np.pi**2* self.t)\n",
    "\n",
    "alpha, beta = 10, 1\n",
    "t0, t1 = 0, 20\n",
    "u_exact = exact_solution(alpha, beta, t0)\n",
    "u_D = fem.Function(V)\n",
    "u_D.interpolate(u_exact)\n",
    "\n",
    "# Dirichlet Boundary Condition\n",
    "tdim = domain.topology.dim\n",
    "fdim = tdim - 1\n",
    "domain.topology.create_connectivity(fdim, tdim)\n",
    "boundary_facets = mesh.exterior_facet_indices(domain.topology)\n",
    "bc = fem.dirichletbc(u_D, fem.locate_dofs_topological(V, fdim, boundary_facets))\n",
    "\n",
    "# Initial Condition\n",
    "u_n = fem.Function(V)\n",
    "u_n.interpolate(u_exact)\n",
    "f = fem.Constant(domain, 0.0)\n",
    "\n",
    "# Variational Form\n",
    "u, v = ufl.TrialFunction(V), ufl.TestFunction(V)\n",
    "dt = 0.05 / 20  # Time step size\n",
    "F = u * v * ufl.dx + dt * ufl.dot(ufl.grad(u), ufl.grad(v)) * ufl.dx - (u_n + dt * f) * v * ufl.dx\n",
    "a = fem.form(ufl.lhs(F))\n",
    "L = fem.form(ufl.rhs(F))\n",
    "\n",
    "# Assembling Matrix\n",
    "A = assemble_matrix(a, bcs=[bc])\n",
    "A.assemble()\n",
    "b = create_vector(L)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23cd4244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 2: Adaptive Integrator and Predictor Setup\n",
    "from adaptive.integrator import Simpson\n",
    "from adaptive.predictor import PredictorQ\n",
    "from adaptive.build_models import build_value_model\n",
    "from adaptive.reward_functions import RewardLog10\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "integrator = Simpson()\n",
    "step_sizes = np.linspace(0.2, 0.5, 11)\n",
    "dim_state = 4\n",
    "dim_action = len(step_sizes)\n",
    "memory = 0\n",
    "tol = 0.0005\n",
    "\n",
    "reward_fun = RewardLog10(error_tol=tol, step_size_range=(step_sizes[0], step_sizes[-1]), reward_range=(0.1, 2))\n",
    "scaler = StandardScaler()\n",
    "scaler.scale_ = np.ones(dim_state)\n",
    "scaler.mean_ = np.zeros(dim_state)\n",
    "predictor = PredictorQ(step_sizes=step_sizes, model=build_value_model(dim_state=dim_state, dim_action=dim_action, memory=memory), scaler=scaler)\n",
    "experience = Experience(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9fdea41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Environment Setup\n",
    "from adaptive.environments import IntegrationEnv\n",
    "from functions import Sinusoid\n",
    "\n",
    "env = IntegrationEnv(fun=Sinusoid(), max_iterations=10000, initial_step_size=step_sizes[0],\n",
    "                     error_tol=tol, nodes_per_integ=3, memory=memory,\n",
    "                     x0=t0, max_dist=t1 - t0, reward_fun=reward_fun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c81c69ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 3: Solver Setup\n",
    "uh = fem.Function(V)\n",
    "solver = PETSc.KSP().create(domain.comm)\n",
    "solver.setOperators(A)\n",
    "solver.setType(PETSc.KSP.Type.PREONLY)\n",
    "solver.getPC().setType(PETSc.PC.Type.LU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c973a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Block 4: Choose Action Function\n",
    "def choose_action(actions, eps, dim_action):\n",
    "    favored = np.argmax(actions)\n",
    "    if np.random.sample() < 0.5 * eps:\n",
    "        return min(favored + 1, dim_action - 1)\n",
    "    elif np.random.sample() < eps:\n",
    "        return max(favored - 1, 0)\n",
    "    else:\n",
    "        return favored\n",
    "gamma = 0  # discount factor for future rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afb8c760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "Episode: 1\n",
      "Episode: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x73b1bc346660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_train_function.<locals>.one_step_on_iterator at 0x73b1bc346660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3\n",
      "Episode: 4\n"
     ]
    }
   ],
   "source": [
    "# Block 5: Time-Stepping Loop with Adaptive Step Sizes\n",
    "for episode in range(5):\n",
    "    state = env.reset(integrator)\n",
    "    done = False\n",
    "    eps = 0.66\n",
    "    print(f'Episode: {episode}')\n",
    "\n",
    "    while not done:\n",
    "        actions = predictor.get_actions(state)\n",
    "        action = choose_action(actions, eps, dim_action)\n",
    "        step_size = predictor.action_to_stepsize(action)\n",
    "\n",
    "        # Update Dirichlet Boundary Condition\n",
    "        u_exact.t += step_size\n",
    "        u_D.interpolate(u_exact)\n",
    "\n",
    "        # Update RHS\n",
    "        with b.localForm() as loc_b:\n",
    "            loc_b.set(0)\n",
    "        assemble_vector(b, L)\n",
    "        apply_lifting(b, [a], [[bc]])\n",
    "        b.ghostUpdate(addv=PETSc.InsertMode.ADD_VALUES, mode=PETSc.ScatterMode.REVERSE)\n",
    "        set_bc(b, [bc])\n",
    "\n",
    "        # Solve Linear Problem\n",
    "        solver.solve(b, uh.vector)\n",
    "        uh.x.scatter_forward()\n",
    "\n",
    "        # Update State and Reward\n",
    "        next_state, reward, done, _ = env.iterate(step_size, integrator)\n",
    "        action_next_state = predictor.get_actions(next_state)\n",
    "        target = reward + gamma * np.max(action_next_state)\n",
    "        target_actions = actions.squeeze()\n",
    "        target_actions[action] = target\n",
    "        experience.append(state=state[0], target=target_actions)\n",
    "\n",
    "        if experience.is_full() or done:\n",
    "            states, targets = experience.get_samples()\n",
    "            loss_predictor = predictor.train_on_batch(states, targets)\n",
    "            experience.reset()\n",
    "\n",
    "        state = next_state.copy()\n",
    "        u_n.x.array[:] = uh.x.array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2219f925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2-error: 4.97e-22\n",
      "H01-error: 2.32e-21\n"
     ]
    }
   ],
   "source": [
    "# Block 6: Error Computation\n",
    "V_ex = fem.functionspace(domain, (\"Lagrange\", 2))\n",
    "u_ex = fem.Function(V_ex)\n",
    "u_ex.interpolate(u_exact)\n",
    "error_L2 = np.sqrt(domain.comm.allreduce(fem.assemble_scalar(fem.form((uh - u_ex)**2 * ufl.dx)), op=MPI.SUM))\n",
    "if domain.comm.rank == 0:\n",
    "    print(f\"L2-error: {error_L2:.2e}\")\n",
    "\n",
    "from dolfinx.fem import form, assemble_scalar\n",
    "from ufl import dot, grad, dx\n",
    "eh = uh - u_ex\n",
    "comm = uh.function_space.mesh.comm\n",
    "error_H10 = form(dot(grad(eh), grad(eh)) * dx)\n",
    "E_H10 = np.sqrt(comm.allreduce(assemble_scalar(error_H10), op=MPI.SUM))\n",
    "if comm.rank == 0:\n",
    "    print(f\"H01-error: {E_H10:.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b658fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advfea",
   "language": "python",
   "name": "advfea"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
